{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcionamiento del notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from page_deep_scraper import page_deep_scraper\n",
    "\n",
    "\n",
    "reity = await page_deep_scraper(\"https://reity.cl\")\n",
    "#tokenit = await page_deep_scraper(\"https://tokenit.cl\")\n",
    "#somosrentable = await page_deep_scraper(\"https://somosrentable.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35164191",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reity[\"pages\"]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrega a la lista solo si el valor no se encuentra ya en la lista\n",
    "def append_unique(lst, value):\n",
    "    if value not in lst:\n",
    "        lst.append(value)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#Entrega lista con todos los links unicos encontrados en en una pagina escrapeada a fondo\n",
    "def all_links_in_deep_scraped_page(deep_scraped):\n",
    "\n",
    "    scraped_urls_list = []\n",
    "    for page in deep_scraped[\"pages\"]:\n",
    "        scraped_urls_list.append(page)\n",
    "    \n",
    "    all_links_in_deep_scraped_page = []\n",
    "    for url in scraped_urls_list:\n",
    "\n",
    "        for link_list in deep_scraped[\"pages\"][url][\"links\"].values():\n",
    "\n",
    "            for link in link_list:\n",
    "                append_unique(all_links_in_deep_scraped_page, link)\n",
    "\n",
    "    return all_links_in_deep_scraped_page\n",
    "\n",
    "\n",
    "\n",
    "r_reity = all_links_in_deep_scraped_page(reity)\n",
    "r_tokenit = all_links_in_deep_scraped_page(tokenit)\n",
    "r_somosrentable = all_links_in_deep_scraped_page(somosrentable)\n",
    "print(r_reity)\n",
    "print(len(r_reity))\n",
    "print(r_tokenit)\n",
    "print(len(r_tokenit))\n",
    "print(r_somosrentable)\n",
    "print(len(r_somosrentable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030503ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from page_deep_scraper import page_scraper \n",
    "from model_builder import all_links_in_deep_scraped_page\n",
    "\n",
    "async def page_deep_scraped_to_dataSources(page_deep_scraped):\n",
    "    \n",
    "    #Crear lista con todos los links a los que se les extrajo links y textos.\n",
    "    list_pages_scraped = []\n",
    "    for page in page_deep_scraped[\"pages\"]:\n",
    "        list_pages_scraped.append(page)\n",
    "\n",
    "    #Crear lista con todos los links de navegacion encontrados en la pagina (Escrapeados o no)\n",
    "    links_in_deep_scraped_page = all_links_in_deep_scraped_page(page_deep_scraped)\n",
    "\n",
    "    #Crear lista de links encontrados en la pagina que no han sido analizados.\n",
    "    set_list_pages_scraped = set(list_pages_scraped)\n",
    "    links_for_scrap = [x for x in links_in_deep_scraped_page if x not in set_list_pages_scraped]\n",
    "\n",
    "    #crea lista de dataSources y agrega data de paginas escrapeadas\n",
    "    dataSources = []\n",
    "    for page_url in list_pages_scraped:\n",
    "        dataSources.append({\n",
    "            \"url\": page_url,\n",
    "            \"links\": page_deep_scraped[\"pages\"][page_url][\"links\"],\n",
    "            \"texts\": page_deep_scraped[\"pages\"][page_url][\"texts\"],\n",
    "        })\n",
    "\n",
    "    #Agrega a dataSources paginas que faltan por scrapear\n",
    "    for links in links_for_scrap:\n",
    "\n",
    "        try:\n",
    "            page_object = await page_scraper(links)\n",
    "\n",
    "            dataSources.append({\n",
    "                \"url\": page_object[\"page\"],\n",
    "                \"links\": page_object[\"links\"],\n",
    "                \"texts\": page_object[\"texts\"],\n",
    "            })\n",
    "        except:\n",
    "            dataSources.append({\n",
    "                \"url\": links,\n",
    "            })\n",
    "        \n",
    "    return dataSources\n",
    "\n",
    "\n",
    "\n",
    "result = await page_deep_scraped_to_dataSources(reity)\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    print(i[\"url\"])\n",
    "    try:\n",
    "        print(i[\"links\"])\n",
    "        print(i[\"texts\"])\n",
    "    except:\n",
    "        pass\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea96d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a54e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_size_mb(d):\n",
    "    b = json.dumps(d, ensure_ascii=False).encode(\"utf-8\")\n",
    "    return len(b) / (1024 * 1024)\n",
    "\n",
    "print(json_size_mb(result), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6412062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcionamiento del notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from model_builder import from_url_model\n",
    "model = from_url_model(\"https://reity.cl\")\n",
    "print(model)\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "for i in model:\n",
    "    print(i[\"slug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[3][\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_pages = []\n",
    "for page in reity[\"pages\"]:\n",
    "    lista_pages.append(page)\n",
    "    \n",
    "\n",
    "for page in lista_pages:\n",
    "    print(page)\n",
    "    print(reity[\"pages\"][page][\"links\"][\"main\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb1d48",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
